{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d44a01-93fb-4fcc-b0e3-7284495ebee1",
   "metadata": {},
   "source": [
    "# Deploy BioSemantics NER model\n",
    "\n",
    "In this notebook we: \n",
    "* Show how to use the fine-tuned NER model do to inference\n",
    "* Rely on the Huggingface `Pipeline` object\n",
    "* Demonstrate how to spin up a GUI using Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb03f84-ce15-4eb9-96eb-991e64b08b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -f ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055872b0-6d1f-4fbf-8855-1382b6545965",
   "metadata": {},
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "b32f6839-d57c-4645-bba2-be5f2b808d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import load_dataset\n",
    "import gradio as gr\n",
    "import os\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ea61f-0146-4106-9508-d9ccc7785f24",
   "metadata": {},
   "source": [
    "### Download checkpoint and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "6989cfe7-7372-42a6-a752-3e0380a7ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Login to HuggingFace\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "f61f672c-4c9e-4143-9141-6ec143da2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the GPU device\n",
    "if torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")   # for M-Series Mac users\n",
    "else:\n",
    "    device = torch.device(\"cuda\")  # CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "3205d53a-07b5-4225-8e70-d4fac267e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"camilothorne/distilbert-base-cased-finetuned-ner-biosem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "d61b02e1-c5c1-4ae9-8341-92e51b05283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b25d1e-2280-4739-8f3c-26ea750536f5",
   "metadata": {},
   "source": [
    "### Run model on an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "be535724-dfbf-4dbc-8d05-974488bf4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classifier = pipeline(\n",
    "    task='ner', model=model, tokenizer=tokenizer, device=device, aggregation_strategy=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d30dc20c-291a-410b-8e58-dcd5d99f3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"The term 'thiol' or 'sulfhydryl', alone or in combination, means a —SH group.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "079f100b-fd5e-4c4b-9d8e-c0669d3bb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = token_classifier(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7ad71901-3760-42a3-b103-e6dfdaede1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-G', 'score': 0.69100636, 'index': 4, 'word': 'th', 'start': 10, 'end': 12}, {'entity': 'B-G', 'score': 0.7451051, 'index': 5, 'word': '##iol', 'start': 12, 'end': 15}, {'entity': 'B-G', 'score': 0.7969378, 'index': 9, 'word': 'su', 'start': 21, 'end': 23}, {'entity': 'B-G', 'score': 0.81136304, 'index': 10, 'word': '##lf', 'start': 23, 'end': 25}, {'entity': 'B-G', 'score': 0.7791597, 'index': 11, 'word': '##hy', 'start': 25, 'end': 27}, {'entity': 'B-G', 'score': 0.8284253, 'index': 12, 'word': '##dr', 'start': 27, 'end': 29}, {'entity': 'B-G', 'score': 0.8167264, 'index': 13, 'word': '##yl', 'start': 29, 'end': 31}]\n"
     ]
    }
   ],
   "source": [
    "print(out1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee97266-8ba1-4035-9057-e80a5cabdc2c",
   "metadata": {},
   "source": [
    "### Note on BPE tokenization and CoNLL\n",
    "\n",
    "The BioSemantics subset used here is formatted in the so-called CoNLL 2003 format, with sentences tokenized\n",
    "as streams of words, i.e. around whitespaces (mostly). BERT models use on the other hard BPE tokenization, i.e.\n",
    "subword tokenization (based on commonly observed morpheme-like subword units). \n",
    "\n",
    "This mismatch in tokenization\n",
    "methodology means that some words and entities may get broken into simpler units. In such cases, the expected\n",
    "behavior is that the label of the original word gets propagated onto its units.\n",
    "\n",
    "Thus, a CoNNL phrase like\n",
    "```bash\n",
    "ether radical wherein the term perfluoroalkyl \n",
    "I-G   O       O       O   O    O                \n",
    "```\n",
    "gets transformed into:\n",
    "```bash\n",
    "et    _her    radical wherein the term _per _f  _lu  _oro _alk _yl\n",
    "I-G   I-G     O       O       O   O    O    O   O    O    O    O           \n",
    "```\n",
    "with `ether` broken into `et` and `_ther`, with the expectation that its original label `I-G` \n",
    "propagates to its constituent units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "67eab5ee-755d-4e07-91f8-2008683222a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_checkpoint = \"camilothorne/biosemantics_uspto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "459671c0-3b0d-4ccc-bbc8-bfc849388d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(datapoint, id2label):\n",
    "    '''\n",
    "    Pretty print sentence.\n",
    "    '''\n",
    "    words = datapoint[\"text\"]\n",
    "    labels = datapoint[\"labels\"]\n",
    "    line1 = \"\"\n",
    "    line2 = \"\"\n",
    "    for word, label in zip(words, labels):\n",
    "        full_label = id2label[label]\n",
    "        max_length = max(len(word), len(full_label))\n",
    "        line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "        line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "    print(line1)\n",
    "    print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "3360c1b3-ad6a-40a2-94e4-7006a60de93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_data = load_dataset(data_checkpoint, field='data', split='test')\n",
    "# Test data labels\n",
    "labs_test  = load_dataset(data_checkpoint, field='maps', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "022dffd1-b46c-4921-a88c-cac08410ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "label_names    = labs_test['tag']\n",
    "id2label       = {i: label for i, label in enumerate(label_names)}\n",
    "label2id       = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "214bf858-4f19-4fa6-bfdf-1991b87bfa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term “ perfluoroalkoxy ” alone or in combination , means a perfluoroalkyl ether radical wherein the term perfluoroalkyl is as defined above \n",
      "O   O    O B-G             O O     O  O  O           O O     O B-G            I-G   O       O       O   O    O              O  O  O       O     \n"
     ]
    }
   ],
   "source": [
    "# In CoNLL, tokenization is done through whitespaces\n",
    "print_example(test_data[100], id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "67302b4f-6a94-4610-aae4-fddf300119e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities detected\n",
    "out2 = token_classifier(' '.join(test_data[100]['text']))\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "c997e57b-7268-46a8-8e8a-9a7584fc6bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-G', 'score': 0.8485372, 'index': 19, 'word': 'per', 'start': 63, 'end': 66}, {'entity': 'B-G', 'score': 0.88328093, 'index': 20, 'word': '##f', 'start': 66, 'end': 67}, {'entity': 'B-G', 'score': 0.878745, 'index': 21, 'word': '##lu', 'start': 67, 'end': 69}, {'entity': 'B-G', 'score': 0.88304514, 'index': 22, 'word': '##oro', 'start': 69, 'end': 72}, {'entity': 'B-G', 'score': 0.8520078, 'index': 23, 'word': '##alk', 'start': 72, 'end': 75}, {'entity': 'B-G', 'score': 0.8779946, 'index': 24, 'word': '##yl', 'start': 75, 'end': 77}, {'entity': 'B-M', 'score': 0.5666113, 'index': 25, 'word': 'et', 'start': 78, 'end': 80}, {'entity': 'B-M', 'score': 0.5932003, 'index': 26, 'word': '##her', 'start': 80, 'end': 83}, {'entity': 'B-G', 'score': 0.63901865, 'index': 32, 'word': '##f', 'start': 112, 'end': 113}, {'entity': 'B-G', 'score': 0.70366, 'index': 33, 'word': '##lu', 'start': 113, 'end': 115}, {'entity': 'B-G', 'score': 0.6144724, 'index': 34, 'word': '##oro', 'start': 115, 'end': 118}, {'entity': 'B-G', 'score': 0.63955724, 'index': 35, 'word': '##alk', 'start': 118, 'end': 121}, {'entity': 'B-G', 'score': 0.7161823, 'index': 36, 'word': '##yl', 'start': 121, 'end': 123}]\n"
     ]
    }
   ],
   "source": [
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "55d1c630-8674-4113-a4a9-b84d5a62a301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'O'), ('term', 'O'), ('“', 'O'), ('per', 'O'), ('##f', 'O'), ('##lu', 'O'), ('##oro', 'O'), ('##alk', 'O'), ('##ox', 'O'), ('##y', 'O'), ('”', 'O'), ('alone', 'O'), ('or', 'O'), ('in', 'O'), ('combination', 'O'), (',', 'O'), ('means', 'O'), ('a', 'O'), ('per', 'B-G'), ('##f', 'B-G'), ('##lu', 'B-G'), ('##oro', 'B-G'), ('##alk', 'B-G'), ('##yl', 'B-G'), ('et', 'B-M'), ('##her', 'B-M'), ('radical', 'O'), ('wherein', 'O'), ('the', 'O'), ('term', 'O'), ('per', 'O'), ('##f', 'B-G'), ('##lu', 'B-G'), ('##oro', 'B-G'), ('##alk', 'B-G'), ('##yl', 'B-G'), ('is', 'O'), ('as', 'O'), ('defined', 'O'), ('above', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# IOB tags overlayed on model tokens\n",
    "tokens = tokenizer.tokenize(example2)\n",
    "inputs = tokenizer.encode(example2, return_tensors=\"pt\").to(device)\n",
    "outputs = model(inputs)[0]\n",
    "predictions = torch.argmax(outputs, dim=2)\n",
    "preds = [id2label[p] for p in predictions[0].tolist()[1:-1]]\n",
    "print([(token, id2label[prediction]) for token, prediction in zip(tokens, predictions[0].tolist()[1:-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc91c84-80cc-4bb9-8c49-1733512104f5",
   "metadata": {},
   "source": [
    "### Create interface/GUI\n",
    "\n",
    "We can use Hugging Face's Gradio support to easily spin a GUI for our NER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a8ec4241-b8ee-4cc0-a61c-e806aa7e5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface.from_pipeline(token_classifier).launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9020b1f-783b-4511-af35-40689e830d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_10_open",
   "language": "python",
   "name": "py3_10_open"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
